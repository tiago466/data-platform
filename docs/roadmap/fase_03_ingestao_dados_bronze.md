# ‚öôÔ∏è FASE 3 ‚Äî INGEST√ÉO DE DADOS (BRONZE / RAW)

<a href="../../README.md" title="Voltar para a p√°gina principal">
üè† Voltar para Home
</a>

## ‚úî TAREFAS DA FASE

- ‚úÖ Analisar procedure legada
- ‚úÖ Identificar fonte OLTP
- ‚úÖ Definir estrat√©gia de extra√ß√£o
- ‚úÖ Criar pipeline de ingest√£o em Python
- ‚úÖ Persistir dados em Parquet (RAW)
- ‚úÖ Implementar logging de execu√ß√£o

---

## üéØ OBJETIVO DA FASE

O objetivo desta fase √© **implementar um processo de ingest√£o de dados moderno**, substituindo abordagens legadas e destrutivas (como ETLs em banco de dados relacional) por um pipeline **ELT**, **imut√°vel**, **versionado** e **audit√°vel**, armazenando os dados na **camada RAW (Bronze)** do Data Lake.

Esta fase estabelece a base de todo o ecossistema de dados, garantindo que os dados brutos sejam tratados como **ativos hist√≥ricos**, preservando rastreabilidade, governan√ßa e possibilidade de reprocessamento futuro.

---

## üß† CONTEXTO E DECIS√ïES INICIAIS

### Aus√™ncia de procedure legada
Inicialmente, este projeto previa a an√°lise de procedures legadas relacionadas ao dom√≠nio de **fluxo operacional**. Contudo, houve uma mudan√ßa estrat√©gica de dom√≠nio para **mercado financeiro**, onde n√£o existia um processo legado formal.

Portanto, esta fase foi constru√≠da **do zero**, permitindo aplicar boas pr√°ticas desde o in√≠cio, sem herdar limita√ß√µes t√©cnicas anteriores.

---

## üîå IDENTIFICA√á√ÉO DA FONTE DE DADOS (OLTP / ORIGEM)

A fonte de dados escolhida foi o **Yahoo Finance**, acessado via biblioteca `yfinance`.

Caracter√≠sticas da fonte:
- Dados hist√≥ricos de ativos financeiros
- Consulta realizada **por ativo**
- Granularidade di√°ria
- Fonte externa (API p√∫blica)

Inicialmente, pretendia-se trabalhar com contratos futuros (WIN, WDO). Entretanto, verificou-se que os dados de mercado futuro no Yahoo Finance s√£o inconsistentes e incompletos, o que poderia comprometer an√°lises e modelos de Machine Learning.

### Decis√£o tomada
Optou-se por trabalhar com **Fundos Imobili√°rios (FIIs)** negociados na B3, pois:
- Os dados s√£o mais consistentes
- A s√©rie hist√≥rica √© mais est√°vel
- O dom√≠nio √© mais adequado para an√°lises de longo prazo e recomenda√ß√£o de investimento

---

## üìã ESTRAT√âGIA DE EXTRA√á√ÉO (METADADOS)

A API do Yahoo Finance exige que as consultas sejam feitas **ativo por ativo**, o que inviabiliza qualquer abordagem manual.

Para resolver esse problema, foi criado um arquivo de metadados: *pipelines/mercado_financeiro/config/ativos.csv*

Este arquivo cont√©m:
- `ticker`: c√≥digo do ativo (ex: HGLG11.SA)
- `type`: tipo do ativo (ex: fii)
- `effective_date`: data inicial da s√©rie hist√≥rica

O `ativos.csv` atua como uma **tabela de controle da ingest√£o**, permitindo:
- Escalabilidade
- Inclus√£o ou exclus√£o de ativos sem alterar c√≥digo
- Reprodutibilidade do pipeline

---

## ‚öôÔ∏è PIPELINE DE INGEST√ÉO (PYTHON)

O pipeline de ingest√£o foi implementado em Python, executado dentro de um container Docker, seguindo o fluxo abaixo:

### Estrutura l√≥gica do pipeline

1. Leitura das vari√°veis de ambiente:
   - `DATA_LAKE_PATH`

2. Leitura do arquivo de metadados (`ativos.csv`)

3. Configura√ß√£o do sistema de logging:
   - Logs em arquivo
   - Logs no console
   - Registro de INFO e ERROR

4. Para cada ativo listado:
   - Registrar in√≠cio da ingest√£o no log
   - Obter ticker, tipo e data inicial
   - Consultar dados hist√≥ricos no Yahoo Finance
   - Validar retorno (DataFrame vazio ou n√£o)
   - Enriquecer os dados com colunas de controle:
     - ativo
     - tipo
     - fonte
     - data_ingestao
   - Definir diret√≥rio RAW baseado em:
     - dom√≠nio
     - fonte
     - tipo
     - ativo
     - data da carga
   - Persistir os dados em formato Parquet
   - Registrar sucesso ou falha no log

O pipeline foi projetado para:
- N√£o interromper a execu√ß√£o em caso de falha de um ativo
- Garantir observabilidade completa da execu√ß√£o
- Facilitar diagn√≥stico de problemas de dados ou da fonte externa

---

## üê≥ AMBIENTE DE EXECU√á√ÉO (DOCKER)

Durante a execu√ß√£o inicial, foi identificado um erro de depend√™ncias (`ModuleNotFoundError: pandas`), pois a imagem `python:3.11-slim` n√£o possui bibliotecas de dados instaladas por padr√£o.

### Solu√ß√£o adotada
- Cria√ß√£o de um `requirements.txt` na raiz do projeto
- Cria√ß√£o de um `Dockerfile` customizado
- Constru√ß√£o de uma imagem pr√≥pria com:
  - pandas
  - yfinance
  - pyarrow (para Parquet)

Essa decis√£o garantiu:
- Ambiente reprodut√≠vel
- Paridade entre desenvolvimento e execu√ß√£o
- Controle expl√≠cito de depend√™ncias

---

## üóÑÔ∏è PERSIST√äNCIA NA CAMADA RAW (BRONZE)

Os dados foram armazenados seguindo rigorosamente os **princ√≠pios fundamentais da camada RAW**:

### Princ√≠pios aplicados

1. **RAW √© imut√°vel**  
   Dados j√° carregados nunca s√£o alterados ou apagados.

2. **RAW √© append-only**  
   Cada nova execu√ß√£o adiciona dados, sem sobrescrever hist√≥rico (exceto reexecu√ß√µes no mesmo dia).

3. **RAW n√£o possui regra de neg√≥cio**  
   Nenhuma transforma√ß√£o, c√°lculo ou regra anal√≠tica √© aplicada.

4. **RAW preserva o formato original**  
   Estrutura e valores retornados pela fonte s√£o mantidos.

5. **RAW √© particionado por tempo**  
   Utiliza√ß√£o do particionamento `dt_carga=YYYY-MM-DD`.

6. **RAW √© organizado por dom√≠nio e fonte**  
   Estrutura clara e naveg√°vel do Data Lake.

### Estrutura resultante

```bash
raw/
‚îî‚îÄ‚îÄ mercado_financeiro/
  ‚îî‚îÄ‚îÄ yahoo_finance/
    ‚îî‚îÄ‚îÄ tipo=fii/
      ‚îî‚îÄ‚îÄ ativo=HGLG11.SA/
        ‚îî‚îÄ‚îÄ dt_carga=2026-01-10/
          ‚îî‚îÄ‚îÄ hglg11.sa_diario.parquet
```

--- 


Execu√ß√µes em dias diferentes criam novos diret√≥rios, preservando o hist√≥rico completo.

---

## üß™ OBSERVABILIDADE E LOGGING

Foi implementado um sistema de logging que registra:

- In√≠cio da ingest√£o de cada ativo
- Sucesso na grava√ß√£o dos dados
- Casos de retorno vazio
- Erros da API (404, ativos deslistados, dados indispon√≠veis)

Exemplo de log:

```log
INFO | Iniciando ingest√£o do ativo HGLG11.SA
INFO | Dados salvos em ...
ERROR | $BCFF11.SA: possibly delisted
INFO | Nenhum dado retornado para BCFF11.SA
```


Esse mecanismo garante:
- Transpar√™ncia do pipeline
- Facilidade de auditoria
- Base para alertas e monitoramento futuro

---

## üì¶ ENTREG√ÅVEIS DA FASE

- Pipeline de ingest√£o em Python
- Arquivo de metadados (`ativos.csv`)
- Estrutura RAW versionada no Data Lake
- Arquivos Parquet persistidos
- Sistema de logging funcional
- Ambiente Docker com runtime customizado

---

## üìù CONCLUS√ÉO DA FASE

Nesta fase, foi consolidado o entendimento de que **a ingest√£o de dados √© o alicerce de toda a arquitetura de dados**. Decis√µes corretas neste est√°gio evitam retrabalho, perda de hist√≥rico e problemas de governan√ßa no futuro.

Ficou claro que:
- Dados devem ser tratados como ativos hist√≥ricos
- A camada RAW n√£o √© um ‚Äúlix√£o‚Äù, mas um reposit√≥rio organizado
- Logging e observabilidade s√£o t√£o importantes quanto o c√≥digo
- Docker e vari√°veis de ambiente s√£o essenciais para reprodutibilidade
- Separar ingest√£o de transforma√ß√£o √© um princ√≠pio fundamental do ELT moderno

O projeto encontra-se, ao final desta fase, **tecnicamente s√≥lido**, com uma base confi√°vel para avan√ßar para a **FASE 4 ‚Äî CURADORIA E TRANSFORMA√á√ÉO (SILVER)**.

---

## üì¨ Contato

**LinkedIn:** [Tiago Lima](https://www.linkedin.com/in/tiago-lima-935049154/)  
**GitHub:** [tiago466](https://github.com/tiago466)

---

<div align="left">
  <a href="#topo" title="Voltar ao in√≠cio do README">‚¨ÜÔ∏è Topo</a>
</div>